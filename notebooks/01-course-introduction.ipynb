{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Introduction: Practical AI - Fall 2024\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Hello and welcome to Practical AI!\n",
    "\n",
    "This is a one semester advanced course on the practical aspects of designing, developing, and deploying artificial intelligence (AI) applications. The course material will cover and apply to a broad span of AI methods and a similarly broad span of applications, with in-depth focus on deep learning enabled perception methods, i.e., methods for using deep neural networks for detecting, classifying, and keeping track of patterns in data. The theory of some common deep learning architectures will be briefly reviewed, but as we will see throughout the semester, knowing the theory of a specific AI technique or architecture in isolation is not enough to enable us to design, develop, and deploy robust systems which perform reliably on constantly changing real-world data.\n",
    "\n",
    "See the course syllabus for information on the course outline, expectations, schedule, and topics. Here we will review some motivating examples which show why it is important to consider the practical aspects of implementing an AI system. Some of these examples may be familiar and some of them may be new. By the end of this course, however, we will have built the concepts to understand all of these examples in depth, and implement mitigations for many of them in the practical AI systems we will design. We will start with a discussion around the relevance of AI to our modern life. We will then look at a few key definitions of technical terms related to AI before moving on to discuss some example challenges that AI systems need to address to perform well in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Context and Motivation\n",
    "\n",
    "Due to the relatively recent prevalence of AI systems, we often hear of the significant impacts (both positive and negative) that the technology will have on our daily lives, and on broader societies. Investors see the prevalence of AI this decade as similar to the \"dot-com Bubble\" in the '90s (CITE), when internet use became widespread. Industry-leading technology companies, including Meta, Alphabet, Apple, Amazon, Netflix, and many others are competing with newer entrants, such as OpenAI, for leadership in this new space. Products we have been familiar with for decades, such as cell-phones and cars, are being augmented with AI capabilities, and AI is increasingly being used in critical industries, such as medicine and defense. For familiar products, like cell-phones, we already see offerings without useful AI augmentation as behind the curve. For example, if introduced in the early 2000s, a chat service like Apple's Siri would have seemed revolutionary compared to legacy chatbot attempts like America Online's (AOL's) SmarterChild (CITE). Today, however, most do not remember SmarterChild and Apple's Siri was lamented by MorningStar as lagging so far behind competing AI technology (e.g., Amazon Alexa) that it was cited as a reason maintain a bear position on Apple stock (CITE)!\n",
    "\n",
    "For products that are familiar to specialists in critical industries like defense and medicine, but perhaps unfamiliar to those outside these fields, the race to reap the benefits of AI technology is equally competitive, often with critical stakes for individuals, groups, and societies. AI has been employed in the Russia-Ukraine and Israel-Palestine conflicts (CITE). Global world powers, including the United States, China, and Russia, are competing for leadership in the technology (CITE), often with different underlying goals (CITE), raising serious ethical considerations with different nations around the world adopting different policies on AI in military applications. In medicine, AI is achieving superhuman performance on many narrow tasks such as cancer screening and disease diagnosis (CITE). However, the tendency for prominent AI techniques to produce the correct answers for the wrong reasons still presents significant risks (CITE). The use of AI in self-driving vehicles has brought many philosophical questions once confined to the classroom (such as the famous trolley problem in ethics) to the heart of engineering design discussions for the specialists who design these systems (CITE). Issues with all-weather sensor reliability, once a goal more important for military applications than civilian applications, now make headlines (CITE) as self-driving cars must accurately discriminate people, objects, and other vehicles, despite challenging weather conditions such as rain, fog, and changes in lighting.\n",
    "\n",
    "As with any new technology, the utility of each AI capability introduced to the world, either through an augmentation to an existing product or as a new product entirely, will come at the plateau of a technology hype-cycle (CITE), i.e., the \"plateau of productivity.\" Similarly, as with other technological advances that impacted critical applications, such as the prevalence of software in modern devices (even those we do not typically think of as computers), the invention of new modes of travel (e.g., sea and air travel), and even the use of electricity itself, the maturation of AI from a field of experimental study to a mature practice suitable for real-world deployment will require AI practitioners adopt and implement a rich repertoire of safeguards. Practitioners will need to adopt these safeguards both proactively, to prevent forseen incidents involving AI technology, and reactively, to ensure lessons learned from previous implementations are not forgotten.\n",
    "\n",
    "The importance of this practice, and the responsibility that we have as a community of practitioners to help mature the AI field to the status of an established discipline can be emphasized by drawing analogies to examples just cited of similar progress in other impactful fields. For a description of the prevalence of software in our modern world and the important responsibility that all software craftspeople have to ensure that code runs smoothly through the adoption of hard-won principles and practices, see Robert C. Martin's Clean Code lectures and book (CITE). For an example of the importance of standards to similarly critical fields, look to the codes of practice that govern aviation manufacturing (CITE), air and sea navigation, and electrical work (i.e., the National Electrical Code). For a growing list of incidents in which AI systems deployed to the real world have caused harms to individuals, groups, and societies, we will continually reference the AI Incident Database (CITE), which maintains a living list of such instances. The incidents documented range from annoyances for users of systems (CITE), to harmful injustices (CITE), and tragic outcomes with injuries and lives lost from those who were not using an AI system directly (CITE). It is not necessary to read or know all these references to proceed with this course (except for those interested!) but it is necessary to realize the role that we all play as AI practitioners in adopting similarly responsible practices as the AI field matures, to prevent reoccurrences of past AI incidents and proactively prevent future AI incidents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Definitions and Terminology\n",
    "\n",
    "Before we discuss some challenges to the implementation of AI systems that perform well in the real world and provide a preview to how this course will help us address these challenges, we need to define some key terms in AI and related fields.\n",
    "\n",
    "### Preliminaries\n",
    "\n",
    "#### Perception\n",
    "\n",
    "#### Action\n",
    "\n",
    "#### Observe-Orient-Decide-Act (OODA) Loops\n",
    "\n",
    "#### Systems\n",
    "\n",
    "#### AI Systems and AI Components\n",
    "\n",
    "#### Whitebox, Blackbox, and Greybox Systems and Methods\n",
    "\n",
    "#### Non-determinism\n",
    "\n",
    "#### Linear and Nonlinear Functions and Systems\n",
    "\n",
    "### Artificial Intelligence (AI)\n",
    "\n",
    "#### Artificial Intelligence\n",
    "\n",
    "#### Machine Learning\n",
    "\n",
    "#### Deep Learning\n",
    "\n",
    "#### Models\n",
    "\n",
    "### Types of Learning\n",
    "\n",
    "#### Supervised Learning\n",
    "\n",
    "#### Unsupervised Learning\n",
    "\n",
    "#### Reinforcement Learning\n",
    "\n",
    "### Types of AI Tasks\n",
    "\n",
    "#### Detection\n",
    "\n",
    "#### Classification\n",
    "\n",
    "#### Semi-supervised and Weakly-Supervised Learning\n",
    "\n",
    "#### Few-shot and Zero-shot Learning\n",
    "\n",
    "### Machine Learning Operations (MLOps)\n",
    "\n",
    "#### Related Term: Development and Security Operations (DevSecOps)\n",
    "\n",
    "#### Data Augmentation\n",
    "\n",
    "#### Data Transformation\n",
    "\n",
    "#### Model Selection\n",
    "\n",
    "#### Continual Learning / Life-long Learning\n",
    "\n",
    "#### Catastrophic Forgetting\n",
    "\n",
    "#### Explainable AI (XAI)\n",
    "\n",
    "#### Confounding Attributes\n",
    "\n",
    "#### Adversarial AI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "Here we will look at some basic examples showing how AI systems can appear to perform well in controlled experiments but exhibit poor performance in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Trusting Correlation\n",
    "\n",
    "Here we see an example where two features appear to be uncorrelated but are really strongly related, and another example where two features appear to be highly correlated but are really unrelated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Poor Software Hygiene\n",
    "\n",
    "Here we see an example where a sneaky bug in our code led us to believe that our system performed much better than it really does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Data Drift\n",
    "\n",
    "Here we see an example where a model performed well initially, but the data distribution changed over time leading to poor performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Noisy Data\n",
    "\n",
    "Here we see an example where noise in the data hurt model performance. Had the model been trained on noisy data, performance would have remained mostly unaffected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: The Veterinary Dentists Rule\n",
    "\n",
    "Here we see a model applied to perform an advanced task in a specialized field (signal processing) without consideration for problems that will affect model performance. These problems would have been obvious to experts in the specialized field of application but likely would go unnoticed by engineers with a typical machine learning background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6: Forgetting Necessary Pre-processing\n",
    "\n",
    "Here we apply a neural network to a simple task (learning to fit a basic mathematical function) as an illustrative example. Surely this will be a task too simple to get wrong!\n",
    "\n",
    "As we will see, the fit is only valid on the domain in which the network was trained. we have no reason to believe the network will be able to extrapolate this function. Besides the illustrated lesson that preprocessing can help to constrain a model inside the domain it was trained, there is a broader lesson in ignoring Ocam's razor and using a model that has too much fitting power for the task. A fit to a fixed equation with unknown parameters generalizes much better!\n",
    "\n",
    "We might be tempted to then conclude that using machine learning tools to approximate mathematical functions is a poor use case, however, there is a rich and useful literature around using machine learning to do just that. These methods are especially useful for expediting the solution of mathematical functions by training a neural network to approximately predict their solution on a GPU. We need to pick our use cases carefully, and weight the risks and benefits of each option when deciding how to approximate a function and whether we should employ machine learning to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7: Learning the Right Result for the Wrong Reason\n",
    "\n",
    "In this example we see an image classifier appear to perform well, but upon further inspection we see that it learned to look at the wrong parts of the image to make its decision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 8: Adversarial Attack\n",
    "\n",
    "Here we see how imperceptible perturbations can be added to an image to completely change the way it is classified by a victim neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lessons Learned\n",
    "\n",
    "As we will continue to see throughout the course, even performing seemingly simple tasks with AI tools can come with risks, and for some tasks AI is not always be the right tool for the job. For more difficult tasks, some challenges to reliable AI deployment in the real world are just beginning to be addressed as the AI field matures. The fields of AI explainability, machine learning operations, and adversarial AI will continue to evolve as the AI field evolves, much in the same way the fields of software engineering, cybersecurity, and other disciplines evolved best practices as they matured over decades. This course will present a snapshot of some of the most important current best practices evolving in the AI field. By the end of this course, students will be able to spot common issues and risks in existing AI systems, and grasp the basic principles needed to design a new AI system from the ground up."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
